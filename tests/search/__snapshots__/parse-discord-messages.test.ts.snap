// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`parse discord messages 1x_Dehalo_v1_Compact 1`] = `
{
  "failed": [
    "**Model Architecture:** Real-ESRGAN Compact",
  ],
  "parsed": {
    "description": "This is a 1x model for removing halos in animation. I was training this a while back and considered it a failed project, but I recently found it useful on a few things I was working on, so I decided to release it. I don't remember any details regarding how it was trained.
https://imgsli.com/MjE3Nzc4",
    "license": "WTFPL",
    "link": "https://mega.nz/file/lBFnHI7K#OGDMb8foOEDsNhXYoIuQIg5N6-2F9-gS9FA0G6lKcc8",
    "name": "Dehalo_v1_Compact",
    "pretrained": "1x-Compact-Pretrain",
    "purpose": "For removing halos in anime.",
    "scale": 1,
  },
}
`;

exports[`parse discord messages 1x-BroadcastToStudio_SPAN 1`] = `
{
  "failed": [],
  "parsed": {
    "architecture": "span",
    "dataset": "SaurusX's BroadcastToStudio dataset",
    "description": "This is SaurusX's original description:
Improvement of low-quality cartoons from broadcast sources. Will greatly increase the visual quality of bad broadcast tape sources of '80s and '90s cartoons (e.g. Garfield and Friends, Heathcliff, DuckTales, etc). Directly addresses chroma blur, dot crawl, and rainbowing. You're highly advised to take care of haloing beforehand in your favorite video editor as the model will not fix it and may make existing halos more noticeable.

-------

Sadly this model has some intense artifacts. Thankfully the SPAN re-train reduced these a bit, but they're still problematic. This was just a quick test of SPAN's capabilities. This was trained only to ~66k iterations, compared to the 480k of the original.",
    "license": "CC-BY-NC-SA-4.0",
    "link": "https://mega.nz/folder/3JIHUbpT#bSsO0RK9MOzjA8dEbl1kbw",
    "name": "BroadcastToStudio_SPAN",
    "pretrained": "1x-span-anime-pretrain",
    "purpose": "Restoring classic cartoons",
    "scale": 1,
    "trainingIterations": 66000,
  },
}
`;

exports[`parse discord messages 2x_span_anime_pretrain 1`] = `
{
  "failed": [
    "Pretrained: trained on basic degradations",
  ],
  "parsed": {
    "architecture": "span",
    "dataset": "HFA2k_LUDVAE modified",
    "description": "This is just a very basic 2x model to start your anime models with on SPAN, nothing special. I tried to keep it as basic as possible",
    "license": "CC0-1.0",
    "link": "https://mega.nz/file/HMZ0jLyL#oRUi6pn53THVgHrqwf1YNYlhaBCEcm9r7EUho9kCOLc",
    "name": "span_anime_pretrain",
    "purpose": "Pretrain to quick start new models",
    "scale": 2,
    "trainingIterations": 67000,
  },
}
`;

exports[`parse discord messages 2xEvangelion_dat2 1`] = `
{
  "failed": [
    "Release Date: 12.02.2024 (dd/mm/yy)",
    "Author: Philip Hofmann",
    "Network: SRVGGNetCompact",
    "Pretrained_Model_G: DAT_2_x2",
  ],
  "parsed": {
    "batchSize": 4,
    "dataset": ""Upscale Archive Evangelion DVD's" by pwnsweet",
    "datasetSize": 3174,
    "description": "For the evangelion upscale project still, this time a dat2 model. A 2x upscaler for evangelion episodes on the evangelion dataset provided by pwnsweet, which called for model trainers to train models on it.

[Slowpoke Pics 4 Examples](https://slow.pics/s/IfJyBnIM)",
    "epoch": 47,
    "hrSize": 128,
    "license": "CC-BY-4.0",
    "link": "https://drive.google.com/drive/folders/1SzyvuIUVHDjNMtapvtDdE3RkDGJsrHd3?usp=drive_link",
    "name": "Evangelion_dat2",
    "otf": false,
    "purpose": "2x upscaler for evangelion episodes",
    "scale": 2,
    "trainingIterations": 196000,
  },
}
`;

exports[`parse discord messages 4x_ditn_w16_pretrain 1`] = `
{
  "failed": [],
  "parsed": {
    "architecture": "ditn",
    "dataset": "nomos_uni",
    "description": "Meant to quick start new DITN models trained on \\\`neosr\\\`. Trained only on downscale degradation (bicubic, bilinear, nearest, lanczos and mitchell).
Note: [Flash Attention](https://github.com/muslll/neosr/blob/master/neosr/archs/ditn_arch.py#L108) breaks inference compatibility with official code.",
    "license": "CC0-1.0",
    "link": "https://drive.google.com/drive/folders/1Fzmuw2xCChAYgX7WznaPcTFpsYdbXBWG?usp=sharing",
    "name": "ditn_w16_pretrain",
    "pretrained": undefined,
    "purpose": "Pretrain to quick start new models.",
    "scale": 4,
    "trainingIterations": 215000,
  },
}
`;

exports[`parse discord messages 4x_span_pretrain 1`] = `
{
  "failed": [
    "**Pretrained**: official pixel loss only pretrained",
  ],
  "parsed": {
    "architecture": "span",
    "dataset": "nomos_uni",
    "description": "Please load it using \\\`strict_load_g: false\\\`. Model trained only on downscale degradation (bicubic, bilinear, nearest, lanczos and mitchell). Can be used to start new SPAN models.",
    "license": "CC0-1.0",
    "link": "https://drive.google.com/drive/folders/17Wyr7yCQhh9GdZcv1KT2oEXuMaV-bGjg?usp=drive_link",
    "name": "span_pretrain",
    "purpose": "Pretrain to quick start new models.",
    "scale": 4,
    "trainingIterations": 430000,
  },
}
`;

exports[`parse discord messages 4x-ClearRealityV1 Soft + Normal 1`] = `
{
  "failed": [
    "**Iterations:** 300k (over multiple models)",
    "**batch_size:** 12-20",
    "**HR_size:** 128-256",
    "**Epoch:** 40?",
    "**OTF Training** No (made with datasetDestroyer)",
    "**Pretrained_Model_G:** Official pretrain",
  ],
  "parsed": {
    "architecture": "span",
    "dataset": "My own UltraSharpV2 dataset, my 8k dataset (v2), Nomos8k, and FaceUp",
    "datasetSize": 19000,
    "description": "Nice to release a model again! This one is intended for realistic imagery, and works especially well on faces, hair, and nature shots. It should only be used on somewhat clear shots, without a lot of grain. I trained this model on SPAN, which as of the time of release, you'll need chaiNNer-nightly for. I aimed for a softer, more natural look for this model with as few artifacts as possible.

In addition to the Normal model, I've included a "soft" model. The Soft model is... softer. Basically it was an earlier version of the model with a more limited dataset. It produces more natural output on games or rendered content, but suffers a bit more with realistic stuff.

Note: In shots with DOF (depth of field) or bokeh, unfortunately there will be artifacts.

**Compatibility:** You'll have to use the [latest chaiNNer-nightly](<https://github.com/chaiNNer-org/chaiNNer-nightly/releases/tag/2023-12-12>) to use this model

<https://imgsli.com/MjI1Nzc5>",
    "license": "CC-BY-NC-SA-4.0",
    "link": "https://mega.nz/folder/Xc4wnC7T#yUS5-9-AbRxLhpdPW_8f2w",
    "name": "ClearRealityV1 Soft + Normal",
    "purpose": "Realistic images of humans, foliage, trees, buildings, etc.",
    "scale": 4,
  },
}
`;

exports[`parse discord messages 4xNomos8kHAT-L_bokeh_jpg 1`] = `
{
  "failed": [],
  "parsed": {
    "architecture": "hat",
    "batchSize": 4,
    "dataset": "nomos8k",
    "datasetSize": 8492,
    "description": "4x photo upscaler, made to specifically handle bokeh effect and jpg compression. Basically a HAT-L variant of the already released 4xNomosUniDAT_bokeh_jpg model, but specifically trained for photos on the nomos8k dataset (and hopefully without the smoothing effect).

The three strengths of this model (design purpose):
Specifically for photos / photography
Handles bokeh effect
Handles jpg compression

This model will not attempt to:
Denoise
Deblur

[Example image](https://slow.pics/c/12rO9MPT) - 4xNomosUniDAT_bokeh_jpg vs 4xNomos8kHAT-L_bokeh_jpg - have a look at the back of the car, for example the WESTFALIA section",
    "epoch": 66,
    "hrSize": 128,
    "license": "CC-BY-4.0",
    "link": "https://drive.google.com/file/d/1VSxJ6rMoaah7hyIqzJsdMLxHIgW5jYNm/view?usp=sharing",
    "name": "Nomos8kHAT-L_bokeh_jpg",
    "otf": false,
    "pretrained": "4x-HAT-L-SRx4-ImageNet-pretrain",
    "purpose": "4x photo upscaler (handles bokeh effect and jpg compression)",
    "scale": 4,
    "trainingIterations": 145000,
  },
}
`;

exports[`parse discord messages 4xNomos8kHAT-L_otf 1`] = `
{
  "failed": [
    "Training time: 60 hours on a remote P100",
  ],
  "parsed": {
    "architecture": "hat",
    "batchSize": 4,
    "dataset": "nomos8k",
    "datasetSize": 8492,
    "description": "4x photo upscaler trained with otf",
    "epoch": 19,
    "hrSize": 128,
    "license": "CC-BY-4.0",
    "link": "https://drive.google.com/file/d/1_7cmypb7d-GGgGwmWmPg8ugJjOozXrFU/view?usp=drive_link",
    "name": "Nomos8kHAT-L_otf",
    "otf": true,
    "pretrained": "4x-HAT-L-SRx4-ImageNet-pretrain",
    "purpose": "4x photo upscaler",
    "scale": 4,
    "trainingIterations": 220000,
  },
}
`;
