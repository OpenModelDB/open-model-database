{
    "name": "eula digimanga bw v2 nc1",
    "author": "eula",
    "license": "CC-BY-NC-SA-4.0",
    "tags": [
        "manga"
    ],
    "description": "Vast improvement over v1 in low frequency detail; moir√© and artifacting reduced significantly and less random noise from JPEG artefacts in the input. Also now only works on 1 channel images, so it runs slightly faster on average and resulting images are much smaller but it might not work on some ESRGAN implementations, I personally recommend using chaiNNer. v1 may still be better in some edge cases.\n\nThere's also a supplementary 1x model that denoises very low quality LRs and smooths halftones so the image works better with the 4x model. Only trained it to help build the dataset and it's useless for already decent-ish LRs but may help you in some situations.",
    "date": "2022-08-17",
    "architecture": "esrgan",
    "size": [
        "64nf",
        "23nb"
    ],
    "scale": 4,
    "inputChannels": 1,
    "outputChannels": 1,
    "resources": [
        {
            "platform": "pytorch",
            "type": "pth",
            "size": 67010885,
            "sha256": "0c3ff9f7b4fc11b21e1262bca06efada0b0723436623db5e2af37fa2291cb750",
            "urls": [
                "https://objectstorage.us-phoenix-1.oraclecloud.com/n/ax6ygfvpvzka/b/open-modeldb-files/o/models%2F4x-eula-digimanga-bw-v2-nc1.pth",
                "https://cdn.discordapp.com/attachments/894310505622155264/1008498310597857290/4x_eula_digimanga_bw_v2_nc1_307k.pth"
            ]
        }
    ],
    "trainingIterations": 307000,
    "trainingBatchSize": 6,
    "trainingHRSize": 384,
    "dataset": "v1's dataset + real-life LRs upscaled with v1",
    "datasetSize": 19019,
    "pretrainedModelG": "4x-eula-digimanga-bw-v1",
    "images": []
}