{
    "name": "sudo rife4 testV1 scale1",
    "author": "sudo",
    "license": "CC-BY-NC-SA-4.0",
    "tags": [
        "image"
    ],
    "description": "Category: Pretrained SOFVSR Models\nPurpose: Animation interpolation\n\nI never really mentioned it in model-releases prior since I think not too many care about interpolation here, but I trained a rife4 model for animation a some months ago, which is better than rife4 and rife4.2 imo. Thought I should also mention it here as well. I also converted it into ncnn. (Nihuis rife ncnn models are only exported with the fastest mode and not the best quality. I exported ncnn models for the most important quality settings. Due to different export/quality settings, there are multiple models. For that reason alone, my ncnn models are much better too, since nihui only exported the fastest one.) My https://github.com/styler00dollar/VSGAN-tensorrt-docker also has the rife ncnn extention, which can use VMAF, dedup, scene detection and so on, which I would recommend. My models are in that extention as well, just select model 10, 11 or 12 and use the dev docker. That test video is done with 2x framerate, enbemble True and FastMode False, combined with scene detection and dedup stuff, tta False. Towards the best quality rife can do. Plz don't steal without credits, k thx.",
    "date": "2022-06-25",
    "architecture": "RIFE",
    "size": null,
    "scale": 2,
    "inputChannels": null,
    "outputChannels": null,
    "resources": [
        {
            "type": "pth",
            "size": 33719173,
            "sha256": "1c9dff599a1c05c38cdc52930a739e7144ce8210fdd098a364e0155c1d23c27c",
            "urls": [
                "https://e1.pcloud.link/publink/show?code=kZfoGRZNuvokO5THhVzVLOt7ocHkR9vDdF7"
            ]
        }
    ],
    "trainingIterations": 269662,
    "pretrainedModelG": {
        "description": "RifeV4"
    }
}