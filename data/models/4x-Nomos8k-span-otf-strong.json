{
    "name": "Nomos8k_span_otf_strong",
    "author": "helaman",
    "license": "CC-BY-4.0",
    "tags": [
        "general-upscaler",
        "photo",
        "restoration"
    ],
    "description": "I release my span otf series:\nThey come in three variations: weak, middle, and strong.\nMainly meant for photos (can be tried on other things of course).\n\n(Also there is a non-otf span model I had been working on simultaneously that I will release shortly, should give better results on less degraded input in comparison to this span otf series)\n\nBasically I trained the otf_strong for 90k iter and then medium and weak based off that, with some more training to de-learn (tone down) the (too?) strong degradations. Used discrim resets to correct occuring colorloss in all of them. gt size was for the most part 512 with batch 9 (since i hoped it would give better results) with 0.55 it/s training speed (first 40k at the beginning were gt size 256 with batch 20 with 0.58 it/s).",
    "date": "2023-12-09",
    "architecture": "span",
    "size": null,
    "scale": 4,
    "inputChannels": 3,
    "outputChannels": 3,
    "resources": [
        {
            "platform": "pytorch",
            "type": "pth",
            "size": 9015866,
            "sha256": "b63dfd3f18da07b46c978f9fb480e6f43f9ece7550ef462c86d5151b93fa6040",
            "urls": [
                "https://drive.google.com/file/d/1K_OUt9lwvDXn280OTfURm0tD3E0lVZ5b/view?usp=drive_link",
                "https://drive.google.com/drive/folders/1zqkuh-RBx7CDUxqmRU2IYyL371re0vwU"
            ]
        },
        {
            "platform": "onnx",
            "type": "onnx",
            "size": 866325,
            "sha256": "5ea41b6280ff98cee6537c0f41c21bf5417328de3330a04845eaab9ec20e55c3",
            "urls": [
                "https://drive.google.com/drive/folders/1zqkuh-RBx7CDUxqmRU2IYyL371re0vwU"
            ]
        }
    ],
    "trainingIterations": 90000,
    "trainingEpochs": 26,
    "trainingBatchSize": 9,
    "trainingHRSize": 256,
    "trainingOTF": true,
    "datasetSize": 8507,
    "pretrainedModelG": "4x-spanx4-ch48",
    "images": [
        {
            "type": "paired",
            "caption": "face",
            "LR": "https://i.slow.pics/pFLYQEHA.webp",
            "SR": "https://i.slow.pics/dnpbw0Jm.webp"
        },
        {
            "type": "paired",
            "caption": "ani_bokeh",
            "LR": "https://i.slow.pics/a7EC1d6D.webp",
            "SR": "https://i.slow.pics/22RY4o5y.webp"
        },
        {
            "type": "paired",
            "caption": "real_degraded",
            "LR": "https://i.slow.pics/gzlsVGMx.webp",
            "SR": "https://i.slow.pics/CnlQB4rK.webp"
        },
        {
            "type": "paired",
            "caption": "noisy",
            "LR": "https://i.slow.pics/RWSRoQQl.webp",
            "SR": "https://i.slow.pics/5OmJVp2n.webp"
        },
        {
            "type": "paired",
            "caption": "BF4",
            "LR": "https://i.slow.pics/Im90vdVx.webp",
            "SR": "https://i.slow.pics/9r2ePWJe.webp"
        },
        {
            "type": "paired",
            "caption": "Control",
            "LR": "https://i.slow.pics/ELIuNgOd.webp",
            "SR": "https://i.slow.pics/YERUChPP.webp"
        }
    ]
}