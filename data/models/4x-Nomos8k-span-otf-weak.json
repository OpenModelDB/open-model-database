{
    "name": "Nomos8k_span_otf_weak",
    "author": "helaman",
    "license": "CC-BY-4.0",
    "tags": [
        "general-upscaler",
        "photo",
        "restoration"
    ],
    "description": "I release my span otf series:\nThey come in three variations: weak, middle, and strong.\nMainly meant for photos (can be tried on other things of course).\n\n(Also there is a non-otf span model I had been working on simultaneously that I will release shortly, should give better results on less degraded input in comparison to this span otf series)\n\nBasically I trained the otf_strong for 90k iter and then medium and weak based off that, with some more training to de-learn (tone down) the (too?) strong degradations. Used discrim resets to correct occuring colorloss in all of them. gt size was for the most part 512 with batch 9 (since i hoped it would give better results) with 0.55 it/s training speed (first 40k at the beginning were gt size 256 with batch 20 with 0.58 it/s).",
    "date": "2023-12-09",
    "architecture": "span",
    "size": null,
    "scale": 4,
    "inputChannels": 3,
    "outputChannels": 3,
    "resources": [
        {
            "platform": "pytorch",
            "type": "pth",
            "size": 9015866,
            "sha256": "26e7ef6483faf93b47f48af262ed4bb8dededa20af34a923e344cb63cafeec0a",
            "urls": [
                "https://drive.google.com/file/d/1KkV23QH3oBAtl88HBKMq88cdWEv0J2hV/view?usp=drive_link",
                "https://drive.google.com/drive/folders/1k6H0z7jD8xzZe2sw_FGVsDLhZY8aTW4n?usp=drive_link"
            ]
        },
        {
            "platform": "onnx",
            "type": "onnx",
            "size": 866325,
            "sha256": "201e588dbca50e008b12725721850c2cd22766f06d81a8379cf58c42eeeb41f1",
            "urls": [
                "https://drive.google.com/drive/folders/1k6H0z7jD8xzZe2sw_FGVsDLhZY8aTW4n?usp=drive_link"
            ]
        }
    ],
    "trainingIterations": 90000,
    "trainingEpochs": 26,
    "trainingBatchSize": 9,
    "trainingHRSize": 256,
    "trainingOTF": true,
    "datasetSize": 8507,
    "pretrainedModelG": "4x-spanx4-ch48",
    "images": [
        {
            "type": "paired",
            "caption": "face",
            "LR": "https://i.slow.pics/pFLYQEHA.webp",
            "SR": "https://i.slow.pics/F95tftGM.webp"
        },
        {
            "type": "paired",
            "caption": "ani_bokeh",
            "LR": "https://i.slow.pics/a7EC1d6D.webp",
            "SR": "https://i.slow.pics/eXkGFkRd.webp"
        },
        {
            "type": "paired",
            "caption": "real_degraded",
            "LR": "https://i.slow.pics/gzlsVGMx.webp",
            "SR": "https://i.slow.pics/v3eO85Zk.webp"
        },
        {
            "type": "paired",
            "caption": "noisy",
            "LR": "https://i.slow.pics/RWSRoQQl.webp",
            "SR": "https://i.slow.pics/bnNlf1f2.webp"
        },
        {
            "type": "paired",
            "caption": "BF4",
            "LR": "https://i.slow.pics/Im90vdVx.webp",
            "SR": "https://i.slow.pics/UQlY2Nv6.webp"
        },
        {
            "type": "paired",
            "caption": "Control",
            "LR": "https://i.slow.pics/ELIuNgOd.webp",
            "SR": "https://i.slow.pics/xuMIRDRk.webp"
        }
    ]
}