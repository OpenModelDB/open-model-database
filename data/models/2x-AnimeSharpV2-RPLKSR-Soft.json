{
    "name": "2x-AnimeSharpV2_RPLKSR_Soft",
    "author": "kim2091",
    "license": "CC-BY-NC-SA-4.0",
    "tags": [
        "anime",
        "compression-removal",
        "restoration"
    ],
    "description": "GitHub Link: https://github.com/Kim2091/Kim2091-Models/releases/tag/2x-AnimeSharpV2_Set\n\nThis is my first anime model in years. Hopefully you guys can find a good use-case for it. Included are 4 models:\n\n1. RealPLKSR (Higher quality, slower)\n2. MoSR (Lower quality, faster)\n\nThere are Sharp and Soft versions of both\nWhen to use each:\n- __Sharp:__ For heavily degraded sources. Sharp models have issues depth of field but are best at removing artifacts \n- __Soft:__ For cleaner sources. Soft models preserve depth of field but may not remove other artifacts as well\n\n__Notes:__\n- MoSR doesn't work in chaiNNer currently\n- To use MoSR:\n  1. Use the ONNX version in tools like [VideoJaNai](<https://github.com/the-database/VideoJaNai>)\n  2. Update spandrel in the latest version of ComfyUI\n\nThe ONNX version may produce slightly different results than the .pth version. If you have issues, try the .pth model.",
    "date": "2024-10-05",
    "architecture": "realplksr",
    "size": null,
    "scale": 2,
    "inputChannels": 3,
    "outputChannels": 3,
    "resources": [
        {
            "platform": "pytorch",
            "type": "pth",
            "size": 29581666,
            "sha256": "a4c2ca131646db2603a061082df726212fa0bcb89031b7d7182a0b7f66e418d9",
            "urls": [
                "https://github.com/Kim2091/Kim2091-Models/releases/download/2x-AnimeSharpV2_Set/2x-AnimeSharpV2_RPLKSR_Soft.pth"
            ]
        },
        {
            "platform": "onnx",
            "type": "onnx",
            "size": 15324988,
            "sha256": "e4177ec9a15dd7219bb4a8b9394ff16a8b97942265ee949ca6c46f90ce4d52e9",
            "urls": [
                "https://github.com/Kim2091/Kim2091-Models/releases/download/2x-AnimeSharpV2_Set/2x-AnimeSharpV2_RPLKSR_Soft_fp16.onnx"
            ]
        }
    ],
    "trainingIterations": 150000,
    "trainingBatchSize": 10,
    "trainingHRSize": 256,
    "trainingOTF": false,
    "dataset": "HFA2k Modified",
    "datasetSize": 3000,
    "images": [
        {
            "type": "paired",
            "LR": "https://i.slow.pics/7JZs9Otd.webp",
            "SR": "https://i.slow.pics/YPeC8Ilj.webp",
            "thumbnail": "/thumbs/small/23727960d429cdfefe554c72.jpg"
        },
        {
            "type": "paired",
            "LR": "https://i.slow.pics/mJZnrE4U.webp",
            "SR": "https://i.slow.pics/h7e3IIGY.webp",
            "thumbnail": "/thumbs/small/0cb92dd69d3a43aed42f1f5f.jpg"
        },
        {
            "type": "paired",
            "LR": "https://i.slow.pics/4RUqHkln.webp",
            "SR": "https://i.slow.pics/vRwR4fZK.webp",
            "thumbnail": "/thumbs/small/770cb8d609d6d63ea7fdacad.jpg"
        }
    ],
    "thumbnail": {
        "type": "paired",
        "LR": "/thumbs/4ac01850e0f0781f95919f26.jpg",
        "SR": "/thumbs/a292bf0aff12be67617edb21.jpg",
        "LRSize": {
            "width": 366,
            "height": 296
        },
        "SRSize": {
            "width": 366,
            "height": 296
        }
    }
}