{
    "name": "2x-AnimeSharpV2_MoSR_Soft",
    "author": "kim2091",
    "license": "CC-BY-NC-SA-4.0",
    "tags": [
        "anime",
        "compression-removal",
        "restoration"
    ],
    "description": "GitHub Link: https://github.com/Kim2091/Kim2091-Models/releases/tag/2x-AnimeSharpV2_Set\n\nThis is my first anime model in years. Hopefully you guys can find a good use-case for it. Included are 4 models:\n\n1. RealPLKSR (Higher quality, slower)\n2. MoSR (Lower quality, faster)\n\nThere are Sharp and Soft versions of both\nWhen to use each:\n- __Sharp:__ For heavily degraded sources. Sharp models have issues depth of field but are best at removing artifacts \n- __Soft:__ For cleaner sources. Soft models preserve depth of field but may not remove other artifacts as well\n\n__Notes:__\n- MoSR doesn't work in chaiNNer currently\n- To use MoSR:\n  1. Use the ONNX version in tools like [VideoJaNai](<https://github.com/the-database/VideoJaNai>)\n  2. Update spandrel in the latest version of ComfyUI\n\nThe ONNX version may produce slightly different results than the .pth version. If you have issues, try the .pth model.",
    "date": "2024-10-05",
    "architecture": "mosr",
    "size": null,
    "scale": 2,
    "inputChannels": 3,
    "outputChannels": 3,
    "resources": [
        {
            "platform": "pytorch",
            "type": "pth",
            "size": 17324914,
            "sha256": "141bd9b90c323f84cbeb17b4238f3b27df29fb43aeb09916aa6791d00e9352e4",
            "urls": [
                "https://github.com/Kim2091/Kim2091-Models/releases/download/2x-AnimeSharpV2_Set/2x-AnimeSharpV2_MoSR_Soft.pth"
            ]
        },
        {
            "platform": "onnx",
            "type": "onnx",
            "size": 8844378,
            "sha256": "e29db0e4b50e0a09b929ad9014ee455802d9f493a82d3d542e6accfccff42743",
            "urls": [
                "https://github.com/Kim2091/Kim2091-Models/releases/download/2x-AnimeSharpV2_Set/2x-AnimeSharpV2_MoSR_Soft_fp16.onnx"
            ]
        }
    ],
    "trainingIterations": 150000,
    "trainingBatchSize": 10,
    "trainingHRSize": 256,
    "trainingOTF": false,
    "dataset": "HFA2k Modified",
    "datasetSize": 3000,
    "images": [
        {
            "type": "paired",
            "LR": "https://i.slow.pics/7JZs9Otd.webp",
            "SR": "https://i.slow.pics/UHvWgH7C.webp",
            "thumbnail": "/thumbs/small/23727960d429cdfefe554c72.jpg"
        },
        {
            "type": "paired",
            "LR": "https://i.slow.pics/mJZnrE4U.webp",
            "SR": "https://i.slow.pics/x0uFFn4T.webp",
            "thumbnail": "/thumbs/small/0cb92dd69d3a43aed42f1f5f.jpg"
        },
        {
            "type": "paired",
            "LR": "https://i.slow.pics/4RUqHkln.webp",
            "SR": "https://i.slow.pics/4jyrfzDy.webp",
            "thumbnail": "/thumbs/small/770cb8d609d6d63ea7fdacad.jpg"
        }
    ],
    "thumbnail": {
        "type": "paired",
        "LR": "/thumbs/4ac01850e0f0781f95919f26.jpg",
        "SR": "/thumbs/ec3c23133c4dcb16cf024eaf.jpg",
        "LRSize": {
            "width": 366,
            "height": 296
        },
        "SRSize": {
            "width": 366,
            "height": 296
        }
    }
}