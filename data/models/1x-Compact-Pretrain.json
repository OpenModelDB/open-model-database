{
    "name": "Compact Pretrain",
    "author": "zarxrax",
    "license": "WTFPL",
    "tags": [
        "image"
    ],
    "description": "Category: Pretrained Models\nPurpose: Pretrained\n\nThis is a collection of pretrained models for Real-ESRGAN's Compact architecture. There are 1x, 2x, and 4x models, as well as 1x and 2x \"UltraCompact\" and \"SuperUltraCompact\" models (think of these as the equivalent to ESRGAN \"lite\" models). By using these are pretrains for your models, you can ensure that your models are able to be interpolated with other Compact models that were trained from these. These pretrains are compatible with most existing compact models.",
    "date": "2022-07-31",
    "architecture": "compact",
    "size": [
        "64nf",
        "16nc"
    ],
    "scale": 1,
    "inputChannels": 3,
    "outputChannels": 3,
    "resources": [
        {
            "platform": "pytorch",
            "type": "pth",
            "size": "d5dff3f43490aaaf1e007445902311034c746ac77363f917f5c15196bfd08dea",
            "sha256": null,
            "urls": [
                "https://objectstorage.us-phoenix-1.oraclecloud.com/n/ax6ygfvpvzka/b/open-modeldb-files/o/models%2F1x-Compact-Pretrain.pth",
                "https://mega.nz/file/Bc0SmIyK#ThTyculaFvrLGMIY8FicUUWBem8O_ZF8LgpPXCn7aVQ"
            ]
        }
    ]
}